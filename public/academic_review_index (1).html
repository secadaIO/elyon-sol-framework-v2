<html><body><p>Authority-Gated AI Governance: A Deterministic Framework for Blocking Overconfident Automation</p><p></p><p>Abstract</p><p>This paper introduces a governance-first AI framework in which epistemic confidence is explicitly decoupled from authority to assert or act. The system enforces a deterministic invariant: absence of domain authority halts automated output regardless of model confidence.</p><p></p><p>1. Design Premise</p><p>AI systems may produce high-confidence outputs without possessing legitimate authority. This framework treats authority absence as a first-class blocking signal.</p><p></p><p>2. Core Components</p><p>Consent FSM, Triadic Authority (T²⁶), Authority Gap Invariant, and OSPF-SAFE safety routing.</p><p></p><p>3. Formal Invariant</p><p>If no authority lens exists for a domain, output is blocked and escalation is mandatory.</p><p></p><p>4. Limitations</p><p>Non-clinical, non-diagnostic, advisory-only. No autonomy transfer.</p></body></html>